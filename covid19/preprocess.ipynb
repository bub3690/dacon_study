{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae239e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34349b3d",
   "metadata": {},
   "source": [
    "# 최대 사이즈 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6032233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav=glob('D:/dacon/covid19/data/train/*.wav')\n",
    "test_wav=glob('D:/dacon/covid19/data/test/*.wav')\n",
    "\n",
    "\n",
    "train_dict = dict()\n",
    "test_dict = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe24cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in train_wav:\n",
    "    file_name = path.split(\"\\\\\")[-1]\n",
    "    \n",
    "    sig, sr = librosa.load(path, sr=sr)# 논문에서 f_s = 16 000HZ\n",
    "    train_dict[file_name] = sig\n",
    "    \n",
    "for path in test_wav:\n",
    "    file_name = path.split(\"\\\\\")[-1]\n",
    "    \n",
    "    sig, sr = librosa.load(path, sr=sr)# 논문에서 f_s = 16 000HZ\n",
    "    test_dict[file_name] = sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa98aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list(train_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0973c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([ val.shape[0]  for val in values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e150d1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243840"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dedb30ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 사이즈 :  243840\n"
     ]
    }
   ],
   "source": [
    "print(\"최대 사이즈 : \",max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa3a9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_dict:\n",
    "    sig = train_dict[key]\n",
    "    pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))\n",
    "    sig = pad1d(sig,max_len)\n",
    "    train_dict[key] = sig\n",
    "    \n",
    "    \n",
    "for key in test_dict:\n",
    "    sig = test_dict[key]\n",
    "    pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))\n",
    "    sig = pad1d(sig,max_len)\n",
    "    test_dict[key] = sig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d6ebcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 시그널\n",
    "\n",
    " \n",
    "## Save pickle\n",
    "with open(\"D:/dacon/covid19/data/pickles/train_dict.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(train_dict, fw)\n",
    "\n",
    "with open(\"D:/dacon/covid19/data/pickles/test_dict.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(test_dict, fw)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "with open(\"D:/dacon/covid19/data/pickles/train_dict.pickle\",\"rb\") as fr:\n",
    "    train_dict = pickle.load(fr)\n",
    "\n",
    "with open(\"D:/dacon/covid19/data/pickles/test_dict.pickle\",\"rb\") as fr:\n",
    "    test_dict = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bec28a",
   "metadata": {},
   "source": [
    "# 노 패딩 시그널\n",
    "\n",
    "- 배치마다 실시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8510a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav=glob('D:/dacon/covid19/data/train/*.wav')\n",
    "test_wav=glob('D:/dacon/covid19/data/test/*.wav')\n",
    "\n",
    "\n",
    "train_dict = dict()\n",
    "test_dict = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff50156",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in train_wav:\n",
    "    file_name = path.split(\"\\\\\")[-1]\n",
    "    \n",
    "    sig, sr = librosa.load(path, sr=sr)# 논문에서 f_s = 16000HZ\n",
    "    train_dict[file_name] = sig\n",
    "    \n",
    "for path in test_wav:\n",
    "    file_name = path.split(\"\\\\\")[-1]\n",
    "    \n",
    "    sig, sr = librosa.load(path, sr=sr)# 논문에서 f_s = 16000HZ\n",
    "    test_dict[file_name] = sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d5b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_dict:\n",
    "    sig = train_dict[key]\n",
    "    train_dict[key] = sig\n",
    "    \n",
    "    \n",
    "for key in test_dict:\n",
    "    sig = test_dict[key]\n",
    "    test_dict[key] = sig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc24937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 시그널\n",
    "\n",
    " \n",
    "## Save pickle\n",
    "with open(\"D:/dacon/covid19/data/pickles/train_dict_nopad.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(train_dict, fw)\n",
    "\n",
    "with open(\"D:/dacon/covid19/data/pickles/test_dict_nopad.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(test_dict, fw)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "712df02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectro mean, std :  -13.326587 14.9956\n",
      "mel mean, std :  -69.00234 15.334582\n",
      "mfcc mean, std :  -2.653834 32.017303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spectro_mean=[]\n",
    "spectro_std=[]\n",
    "\n",
    "mel_mean=[]\n",
    "mel_std=[]\n",
    "\n",
    "mfcc_mean=[]\n",
    "mfcc_std=[]\n",
    "\n",
    "\n",
    "for key in train_dict.keys():\n",
    "    #print(key)\n",
    "    sig =  train_dict[key] # 16000hz 실시\n",
    "    #length=29990 #300 padding을 위한 파라미터\n",
    "    #pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "    #sig = pad1d(sig,length)\n",
    "    sig = (sig-sig.mean())/sig.std()\n",
    "    \n",
    "\n",
    "\n",
    "    MFCCs = librosa.feature.mfcc(y=sig, sr=sr,win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=128)\n",
    "\n",
    "    stft = librosa.stft(sig, win_length=win_length,n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    mel_feature = librosa.feature.melspectrogram(y=sig,sr=sr,hop_length=hop_length,n_fft=n_fft)\n",
    "    mel_feature = librosa.core.power_to_db(mel_feature,ref=np.max)\n",
    "    #mel_feature=librosa.util.normalize(mel_feature) # l-infinity norm\n",
    "\n",
    "    #stft 300 FRAME이 되도록 패딩.\n",
    "    #length = 300\n",
    "\n",
    "    magnitude = np.abs(stft)\n",
    "    log_spectrogram = librosa.amplitude_to_db(magnitude)\n",
    "    #log_spectrogram = librosa.util.normalize(log_spectrogram) # l-infinity norm\n",
    "\n",
    "\n",
    "    #padding\n",
    "    #pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "    #log_spectrogram = pad2d(log_spectrogram, length)\n",
    "    #mel_feature = pad2d(mel_feature, length)\n",
    "\n",
    "    #MFCCs = pad2d(MFCCs, length) # mfcc 대신 encoder를 가져와서 해보자.\n",
    "    log_spectrogram=log_spectrogram[:128,:]# 224 x 300 으로 사이즈 조절\n",
    "    \n",
    "    #print(value[0])\n",
    "    spectro_mean.append(log_spectrogram.mean()) # spectrogram\n",
    "    spectro_std.append(log_spectrogram.std()) # spectrogram\n",
    "    \n",
    "    #print(value[0])\n",
    "    mel_mean.append(mel_feature.mean()) # spectrogram\n",
    "    mel_std.append(mel_feature.std()) # spectrogram\n",
    "    \n",
    "    #print(value[0])\n",
    "    mfcc_mean.append(MFCCs.mean()) # spectrogram\n",
    "    mfcc_std.append(MFCCs.std()) # spectrogram    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print('spectro mean, std : ',np.mean(spectro_mean),np.mean(spectro_std))\n",
    "print('mel mean, std : ',np.mean(mel_mean),np.mean(mel_std))\n",
    "print('mfcc mean, std : ',np.mean(mfcc_mean),np.mean(mfcc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a15aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a8f7eb",
   "metadata": {},
   "source": [
    "# train set norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953fb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
