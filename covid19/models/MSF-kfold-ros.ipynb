{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6198c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import librosa, librosa.display \n",
    "\n",
    "p = os.path.abspath('../') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 상위 폴더에 추가된 모듈.\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3ac0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a66d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "FIG_SIZE = (15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15fee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"D:/dacon/covid19/data/train_data.csv\")\n",
    "test_df=pd.read_csv(\"D:/dacon/covid19/data/test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7318abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "import pickle\n",
    "with open(\"D:/dacon/covid19/data/pickles/train_dict.pickle\",\"rb\") as fr:\n",
    "    train_dict = pickle.load(fr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b334d3",
   "metadata": {},
   "source": [
    "# train/valid 나누기 (stratified kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a692f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy :  3499\n",
      "Covid:  306\n",
      "총 데이터수 :  3805\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "\n",
    "healthy = list(train_df[train_df['covid19']==0]['id'])\n",
    "covid = list(train_df[train_df['covid19']==1]['id'])\n",
    "print(\"Healthy : \",len(healthy))\n",
    "print(\"Covid: \",len(covid))\n",
    "\n",
    "X = healthy+covid # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<3499:\n",
    "        Y.append(\"healthy\")\n",
    "    else:\n",
    "        Y.append(\"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04f42c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'covid': 245, 'healthy': 2799}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'covid': 61, 'healthy': 700} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'covid': 245, 'healthy': 2799}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'covid': 61, 'healthy': 700} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'covid': 245, 'healthy': 2799}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'covid': 61, 'healthy': 700} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'covid': 245, 'healthy': 2799}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'covid': 61, 'healthy': 700} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'covid': 244, 'healthy': 2800}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'covid': 62, 'healthy': 699} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=123)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30482d66",
   "metadata": {},
   "source": [
    "랜덤 오버 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05b298b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(5):\\n    X_temp = np.array(X_train_list[i]).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\\n    #Y = np.array(Y)\\n    ros = RandomOverSampler(random_state = 123)\\n    X_res,Y_res = ros.fit_resample(X_temp,Y_train_list[i])\\n    \\n    print(\"\\n fold{} \".format(i))\\n    print(\\'before dataset shape {}\\'.format(Counter(Y_train_list[i])) )\\n    print(\\'Resampled dataset shape {}\\'.format(Counter(Y_res)) )   \\n    \\n    #원래대로 돌리기\\n    X_res=X_res.reshape(1, -1)\\n    X_train_list[i]=X_res[0].tolist()\\n    Y_train_list[i]=Y_res\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. random over sampling\n",
    "\n",
    "for i in range(5):\n",
    "    X_temp = np.array(X_train_list[i]).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "    #Y = np.array(Y)\n",
    "    ros = RandomOverSampler(random_state = 123)\n",
    "    X_res,Y_res = ros.fit_resample(X_temp,Y_train_list[i])\n",
    "    \n",
    "    print(\"\\n fold{} \".format(i))\n",
    "    print('before dataset shape {}'.format(Counter(Y_train_list[i])) )\n",
    "    print('Resampled dataset shape {}'.format(Counter(Y_res)) )   \n",
    "    \n",
    "    #원래대로 돌리기\n",
    "    X_res=X_res.reshape(1, -1)\n",
    "    X_train_list[i]=X_res[0].tolist()\n",
    "    Y_train_list[i]=Y_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7cd0e",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72193746",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20700/1140290761.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"healthy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"covid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwin_length\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 1250\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mwin_length\u001b[0m \u001b[1;31m# WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"healthy\",\"covid\"]\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "class covid_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None,augment=None,normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = covid_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.augment=augment\n",
    "        self.normalize=normalize\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "    \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        num = self.path_list[idx]\n",
    "        num_str = str(num)   \n",
    "        sig = train_dict[num_str.zfill(5)+'.wav']\n",
    "        length_of_sig = sig.shape[0]\n",
    "        \n",
    "        length=243840 #300 padding을 위한 파라미터\n",
    "        pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "        sig = pad1d(sig,length)        \n",
    "        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###        \n",
    "        \n",
    "        \n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(y=sig, sr=sr,win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=21)\n",
    "        \n",
    "        \n",
    "        stft = librosa.stft(sig, win_length=win_length,n_fft=n_fft, hop_length=hop_length)        \n",
    "        magnitude = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(magnitude)        \n",
    "        log_spectrogram=log_spectrogram[:128,:]# 224 x 300 으로 사이즈 조절        \n",
    "        \n",
    "        mel_feature = librosa.feature.melspectrogram(y=sig,sr=sr,hop_length=hop_length,n_fft=n_fft)\n",
    "        mel_feature = librosa.core.power_to_db(mel_feature,ref=np.max)\n",
    "        #mel_feature=librosa.util.normalize(mel_feature) # l-infinity norm\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            log_spectrogram=self.transform(log_spectrogram).type(torch.float32)# 타입 변화\n",
    "            mel_feature=self.transform(mel_feature).type(torch.float32)\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 타입 변화\n",
    "            MSF = torch.stack([log_spectrogram,mel_feature,MFCCs])# 3채널로 복사.\n",
    "            if self.training:\n",
    "                MSF=self.augment(MSF)\n",
    "            MSF = MSF.squeeze(dim=1)\n",
    "            # global normalize\n",
    "            if self.normalize:\n",
    "                MSF=self.normalize(MSF)\n",
    "            \n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            # 사용안함.\n",
    "            mel_feature = torch.from_numpy(mel_feature).type(torch.float32)\n",
    "            mel_feature=mel_feature.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MSF, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ad041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  32 #한 배치당 16개 음성데이터\n",
    "EPOCHS = 40 # 전체 데이터 셋을 50번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2fddc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           covid_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정. to tensor는 -데이터는 노멀라이즈못함.\n",
    "                                               data_num=0,\n",
    "                                               training=True,\n",
    "                                               augment = transforms.Compose([\n",
    "                                                   T.TimeMasking(time_mask_param=120),\n",
    "                                                   T.FrequencyMasking(freq_mask_param=13)\n",
    "                                               ]),\n",
    "                                               normalize=transforms.Normalize((-13.326587 , -69.00234,-2.653834), (14.9956,15.334582,32.017303)),\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           \n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           covid_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               normalize=transforms.Normalize((-13.326587 , -69.00234,-2.653834), (14.9956,15.334582,32.017303)),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c37b27",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4887d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([32, 3, 128, 2439]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([32]) type: torch.LongTensor\n",
      "healthy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(classes[Y_train[0]])\n",
    "plt.imshow(X_train[0].view(128,-1,3).numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(\"MSF\")\n",
    "plt.show()\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd7b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([32, 3, 128, 2439]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([32]) type: torch.LongTensor\n",
      "healthy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Spectrogram (dB)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(classes[Y_valid[0]])\n",
    "librosa.display.specshow(X_valid[0][0].numpy(), sr=sr, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(\"Spectrogram (dB)\")\n",
    "\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102265d1",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea6954d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda()\n",
    "        \n",
    "        self.model.ftrs = self.model.fc.in_features # in_features : fully connected의 입력수.\n",
    "        self.num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        res_feature=self.model(x)\n",
    "        return res_feature\n",
    "\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    #model=se_resnet18().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b0b6b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResLayer(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=50, bias=True)\n",
      "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Dropout(p=0.5, inplace=False)\n",
      "      (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 여기는 반영 안됨.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af6e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a93c433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d599a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               covid_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True,\n",
    "                                                   normalize=transforms.Normalize((-13.326587 , -69.00234,-2.653834), (14.9956,15.334582,32.017303)),\n",
    "                                                   augment = transforms.Compose([\n",
    "                                                       T.TimeMasking(time_mask_param=240),\n",
    "                                                       T.FrequencyMasking(freq_mask_param=13)\n",
    "                                               ]),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               covid_dataset(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   normalize=transforms.Normalize((-13.326587 , -69.00234,-2.653834), (14.9956,15.334582,32.017303)),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e46a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/checkpoint_MSF_resnet18_true_pos_1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0250\t Train Acc:49.15 %  | \tValid Loss:0.0218 \tValid Acc: 71.48 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.021800).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0228\t Train Acc:57.59 %  | \tValid Loss:0.0218 \tValid Acc: 80.16 %\n",
      "\n",
      "Validation loss decreased (0.021800 --> 0.021773).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0227\t Train Acc:67.54 %  | \tValid Loss:0.0216 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021773 --> 0.021552).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0229\t Train Acc:71.25 %  | \tValid Loss:0.0219 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0228\t Train Acc:70.47 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0219\t Train Acc:67.87 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0222\t Train Acc:75.13 %  | \tValid Loss:0.0215 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021552 --> 0.021544).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0221\t Train Acc:83.90 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0220\t Train Acc:71.85 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0219\t Train Acc:76.25 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0217\t Train Acc:84.13 %  | \tValid Loss:0.0216 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0221\t Train Acc:81.24 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_MSF_resnet18_true_pos_2.pt\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0234\t Train Acc:52.79 %  | \tValid Loss:0.0220 \tValid Acc: 56.50 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022008).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0228\t Train Acc:59.07 %  | \tValid Loss:0.0229 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0224\t Train Acc:61.47 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.022008 --> 0.021724).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0230\t Train Acc:68.43 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0222\t Train Acc:75.79 %  | \tValid Loss:0.0216 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021724 --> 0.021564).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0220\t Train Acc:74.77 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0221\t Train Acc:81.14 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0219\t Train Acc:82.79 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0216\t Train Acc:80.98 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0221\t Train Acc:74.01 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_MSF_resnet18_true_pos_3.pt\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0228\t Train Acc:51.77 %  | \tValid Loss:0.0218 \tValid Acc: 90.67 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.021792).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0231\t Train Acc:62.91 %  | \tValid Loss:0.0219 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0228\t Train Acc:65.93 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021792 --> 0.021786).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0222\t Train Acc:74.44 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0222\t Train Acc:68.59 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021786 --> 0.021776).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0221\t Train Acc:75.43 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021776 --> 0.021737).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0222\t Train Acc:77.56 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021737 --> 0.021678).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0220\t Train Acc:83.25 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0221\t Train Acc:74.11 %  | \tValid Loss:0.0217 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0220\t Train Acc:82.19 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0219\t Train Acc:83.41 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0216\t Train Acc:84.92 %  | \tValid Loss:0.0216 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021678 --> 0.021611).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0220\t Train Acc:85.74 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0217\t Train Acc:79.43 %  | \tValid Loss:0.0216 \tValid Acc: 89.88 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0220\t Train Acc:81.34 %  | \tValid Loss:0.0219 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0218\t Train Acc:84.13 %  | \tValid Loss:0.0222 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0218\t Train Acc:89.26 %  | \tValid Loss:0.0218 \tValid Acc: 90.01 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_MSF_resnet18_true_pos_4.pt\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0243\t Train Acc:58.94 %  | \tValid Loss:0.0242 \tValid Acc: 26.15 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.024250).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0227\t Train Acc:61.63 %  | \tValid Loss:0.0218 \tValid Acc: 90.93 %\n",
      "\n",
      "Validation loss decreased (0.024250 --> 0.021752).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0223\t Train Acc:63.86 %  | \tValid Loss:0.0221 \tValid Acc: 90.54 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0221\t Train Acc:65.44 %  | \tValid Loss:0.0217 \tValid Acc: 74.38 %\n",
      "\n",
      "Validation loss decreased (0.021752 --> 0.021705).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0224\t Train Acc:71.68 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0223\t Train Acc:66.72 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0219\t Train Acc:76.31 %  | \tValid Loss:0.0215 \tValid Acc: 91.98 %\n",
      "\n",
      "Validation loss decreased (0.021705 --> 0.021457).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0223\t Train Acc:65.80 %  | \tValid Loss:0.0218 \tValid Acc: 91.98 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0220\t Train Acc:65.57 %  | \tValid Loss:0.0217 \tValid Acc: 89.75 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0219\t Train Acc:75.33 %  | \tValid Loss:0.0215 \tValid Acc: 67.67 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0219\t Train Acc:75.43 %  | \tValid Loss:0.0216 \tValid Acc: 76.35 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0217\t Train Acc:79.47 %  | \tValid Loss:0.0217 \tValid Acc: 74.38 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_MSF_resnet18_true_pos_5.pt\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0230\t Train Acc:41.36 %  | \tValid Loss:0.0220 \tValid Acc: 8.28 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022005).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0227\t Train Acc:49.21 %  | \tValid Loss:0.0219 \tValid Acc: 11.43 %\n",
      "\n",
      "Validation loss decreased (0.022005 --> 0.021880).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0227\t Train Acc:60.81 %  | \tValid Loss:0.0220 \tValid Acc: 49.67 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0223\t Train Acc:68.82 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "Validation loss decreased (0.021880 --> 0.021757).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0223\t Train Acc:68.66 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:6]\t Train Loss:0.0221\t Train Acc:64.49 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0219\t Train Acc:77.99 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0218\t Train Acc:81.87 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0222\t Train Acc:82.06 %  | \tValid Loss:0.0217 \tValid Acc: 91.85 %\n",
      "\n",
      "Validation loss decreased (0.021757 --> 0.021709).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0221\t Train Acc:82.88 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0219\t Train Acc:85.12 %  | \tValid Loss:0.0219 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0220\t Train Acc:85.68 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0216\t Train Acc:87.22 %  | \tValid Loss:0.0218 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0216\t Train Acc:88.73 %  | \tValid Loss:0.0217 \tValid Acc: 91.85 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = './checkpoint/checkpoint_MSF_resnet18_true_pos_'+str(data_ind)+'.pt'\n",
    "    print(check_path)\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "        \n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66889691",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32170a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 75.1314 |\t valid ACC: 91.9842 \n",
      "[2 교차검증] train ACC : 75.7884 |\t valid ACC: 91.9842 \n",
      "[3 교차검증] train ACC : 84.9212 |\t valid ACC: 91.9842 \n",
      "[4 교차검증] train ACC : 76.3141 |\t valid ACC: 91.9842 \n",
      "[5 교차검증] train ACC : 82.0631 |\t valid ACC: 91.8528 \n",
      "평균 검증 정확도 91.95795006570302 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940303e7",
   "metadata": {},
   "source": [
    "# TEST 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "243c84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=list(test_df['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae30594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/dacon/covid19/data/pickles/test_dict.pickle\",\"rb\") as fr:\n",
    "    test_dict = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6a69b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "classes = [\"healthy\",\"covid\"]\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) # 400\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "class covid_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes,transform=None,normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        num = self.path_list[idx]\n",
    "        num_str = str(num)   \n",
    "        sig = test_dict[num_str.zfill(5)+'.wav']\n",
    "        length_of_sig = sig.shape[0]\n",
    "        \n",
    "        length=243840 #300 padding을 위한 파라미터\n",
    "        pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "        sig = pad1d(sig,length)        \n",
    "        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###        \n",
    "        \n",
    "        \n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(y=sig, sr=sr,win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=128)\n",
    "        \n",
    "        \n",
    "        stft = librosa.stft(sig, win_length=win_length,n_fft=n_fft, hop_length=hop_length)        \n",
    "        magnitude = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(magnitude)        \n",
    "        log_spectrogram=log_spectrogram[:128,:]# 224 x 300 으로 사이즈 조절        \n",
    "        \n",
    "        mel_feature = librosa.feature.melspectrogram(y=sig,sr=sr,hop_length=hop_length,n_fft=n_fft)\n",
    "        mel_feature = librosa.core.power_to_db(mel_feature,ref=np.max)\n",
    "        #mel_feature=librosa.util.normalize(mel_feature) # l-infinity norm\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            log_spectrogram=self.transform(log_spectrogram).type(torch.float32)# 타입 변화\n",
    "            mel_feature=self.transform(mel_feature).type(torch.float32)\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 타입 변화\n",
    "            MSF = torch.stack([log_spectrogram,mel_feature,MFCCs])# 3채널로 복사.\n",
    "            if self.training:\n",
    "                MSF=self.augment(MSF)\n",
    "            MSF = MSF.squeeze(dim=1)\n",
    "            # global normalize\n",
    "            if self.normalize:\n",
    "                MSF=self.normalize(MSF)\n",
    "            \n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            # 사용안함.\n",
    "            mel_feature = torch.from_numpy(mel_feature).type(torch.float32)\n",
    "            mel_feature=mel_feature.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MSF,num\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1161f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               covid_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   normalize=transforms.Normalize((-13.326587 , -69.00234,-2.653834), (14.9956,15.334582,32.017303)),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = False,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54f7dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    num_list = []\n",
    "    predictions = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image,num in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            output = model(image)\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            predictions +=prediction\n",
    "            num_list += num\n",
    "            \n",
    "        return predictions,num_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b824b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction = pd.read_csv(\"D:/dacon/covid19/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d32cab8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18240/2538863409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msample_prediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'covid19'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18240/4068106486.py\u001b[0m in \u001b[0;36mtest_evaluate\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#no_grad : 그래디언트 값 계산 막기.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18240/565254395.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mMFCCs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMFCCs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 타입 변화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mMSF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlog_spectrogram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmel_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMFCCs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 3채널로 복사.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[0mMSF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mMSF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attribute_name)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "    \n",
    "    check_path = './checkpoint/checkpoint_MSF_resnet18_true_ros_'+str(data_ind)+'.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions, num_list = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    sample_prediction['covid19'] = [dat.item() for dat in predictions]\n",
    "    file_name = \"D:/dacon/covid19/\"+str(data_ind)+\"_result.csv\"\n",
    "    sample_prediction.to_csv(file_name,index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997d91b",
   "metadata": {},
   "source": [
    "\n",
    "- 0619\n",
    "1. 나이, 병 유무 데이터 넣어서 다시 학습하기.\n",
    "2. specaugment 추가하기.\n",
    "3. random oversampling\n",
    "4. 시간되면, 배치별로 패딩으로 수정하기."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
