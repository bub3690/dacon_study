{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae1bd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f7f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af139e",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "```\n",
    "\n",
    "TurbID - 발전기 ID\n",
    "\n",
    "Day - 날짜\n",
    "\n",
    "Tmstamp - 시간\n",
    "\n",
    "Wspd - 풍속\n",
    "\n",
    "Wdir - 터빈이 바라보는 각도와 실제 바람 방향 각도 차이\n",
    "\n",
    "Etmp - 외부 온도\n",
    "\n",
    "Itmp - 터빈 내부 온도\n",
    "\n",
    "Ndir - 터빈이 바라보는 방향 각도\n",
    "\n",
    "Pab - 터빈 당 3개의 날이 있으며 각각의 각도가 다름\n",
    "\n",
    "Prtv - 무효전력 : 에너지원을 필요로 하지 않는 전력\n",
    "\n",
    "Patv - 유효전력 : 실제로 터빈을 돌리는 일을 하는 전력\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "베이스 라인 제공 전처리 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c000a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_data.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0839be7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TurbID         0\n",
       "Day            0\n",
       "Tmstamp        0\n",
       "Wspd       45587\n",
       "Wdir       45587\n",
       "Etmp       45587\n",
       "Itmp       45587\n",
       "Ndir       45587\n",
       "Pab1       45587\n",
       "Pab2       45587\n",
       "Pab3       45587\n",
       "Prtv       45587\n",
       "Patv       45587\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data의 결측값 확인\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3dbb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TurbID     0\n",
      "Day        0\n",
      "Tmstamp    0\n",
      "Wspd       0\n",
      "Wdir       0\n",
      "Etmp       0\n",
      "Itmp       0\n",
      "Ndir       0\n",
      "Pab1       0\n",
      "Pab2       0\n",
      "Pab3       0\n",
      "Prtv       0\n",
      "Patv       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# method : 결측값을 변경할 방식입니다. bfill로 할경우 결측값을 바로 아래 값과 동일하게 변경합니다.\n",
    "# 결측값 처리\n",
    "train_data = train_data.fillna(method = 'bfill')\n",
    "\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59356c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23:10</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.49</td>\n",
       "      <td>28.71</td>\n",
       "      <td>42.53</td>\n",
       "      <td>-9.44</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>1330.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23:20</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>28.59</td>\n",
       "      <td>42.56</td>\n",
       "      <td>-8.17</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>1550.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23:30</td>\n",
       "      <td>12.66</td>\n",
       "      <td>1.09</td>\n",
       "      <td>28.54</td>\n",
       "      <td>42.23</td>\n",
       "      <td>-8.17</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1549.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23:40</td>\n",
       "      <td>12.58</td>\n",
       "      <td>1.70</td>\n",
       "      <td>28.48</td>\n",
       "      <td>42.09</td>\n",
       "      <td>-8.17</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1549.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23:50</td>\n",
       "      <td>9.95</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>28.31</td>\n",
       "      <td>42.09</td>\n",
       "      <td>-8.17</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1361.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TurbID  Day Tmstamp   Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0         1    1   00:00   6.17 -3.99  30.73  41.80  25.92  1.00  1.00  1.00   \n",
       "1         1    1   00:10   6.17 -3.99  30.73  41.80  25.92  1.00  1.00  1.00   \n",
       "2         1    1   00:20   6.27 -2.18  30.60  41.63  20.91  1.00  1.00  1.00   \n",
       "3         1    1   00:30   6.42 -0.73  30.52  41.52  20.91  1.00  1.00  1.00   \n",
       "4         1    1   00:40   6.25  0.89  30.49  41.38  20.91  1.00  1.00  1.00   \n",
       "..      ...  ...     ...    ...   ...    ...    ...    ...   ...   ...   ...   \n",
       "139       1    1   23:10   9.95  0.49  28.71  42.53  -9.44  1.02  1.02  1.02   \n",
       "140       1    1   23:20  12.20  0.70  28.59  42.56  -8.17  1.08  1.08  1.08   \n",
       "141       1    1   23:30  12.66  1.09  28.54  42.23  -8.17  1.08  1.08  1.08   \n",
       "142       1    1   23:40  12.58  1.70  28.48  42.09  -8.17  1.08  1.08  1.08   \n",
       "143       1    1   23:50   9.95 -0.42  28.31  42.09  -8.17  1.01  1.01  1.01   \n",
       "\n",
       "     Prtv     Patv  \n",
       "0   -0.25   494.66  \n",
       "1   -0.25   494.66  \n",
       "2   -0.24   509.76  \n",
       "3   -0.26   542.53  \n",
       "4   -0.23   509.36  \n",
       "..    ...      ...  \n",
       "139 -0.29  1330.24  \n",
       "140 -0.23  1550.74  \n",
       "141 -0.21  1549.66  \n",
       "142 -0.20  1549.64  \n",
       "143 -0.20  1361.95  \n",
       "\n",
       "[144 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(train_data[\"TurbID\"]==1)&(train_data[\"Day\"]==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1111f49",
   "metadata": {},
   "source": [
    "# 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f71a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 Turb당 194 line\n",
    "# label은 2일.로 나눠야함.\n",
    "\n",
    "def make_train_data(data):\n",
    "    train_x, train_y = [], []\n",
    "    for i in tqdm(sorted(pd.unique(data[\"TurbID\"]))):\n",
    "        tmp_data = data[data[\"TurbID\"] == i]\n",
    "        for j in range(1, 195): # 1~195 (1~194까지?)\n",
    "            \n",
    "            # train data ==> 5일 단위\n",
    "            # label data ==> 2일 단위\n",
    "            day_list = [x for x in range(j, j+ 5)]\n",
    "            label_day_list = [y for y in range(j+5, j + 7)]\n",
    "            \n",
    "            train_tmp = tmp_data[tmp_data[\"Day\"].isin(day_list)]\n",
    "            label_tmp = tmp_data[tmp_data[\"Day\"].isin(label_day_list)][\"Patv\"]\n",
    "            \n",
    "            # feature 선택 및 제거\n",
    "            train_tmp = train_tmp.drop([\"TurbID\", \"Day\"], axis = 1)\n",
    "            \n",
    "            train_x.append(np.array(train_tmp))\n",
    "            train_y.append(np.array(label_tmp))\n",
    "            \n",
    "    return train_x, train_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9de5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 134/134 [00:23<00:00,  5.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# time stamp label encoding\n",
    "tms_list = list(pd.unique(train_data[\"Tmstamp\"]))\n",
    "\n",
    "train_data[\"Tmstamp\"] = train_data[\"Tmstamp\"].apply(lambda x : tms_list.index(x))\n",
    "\n",
    "X_data, Y_data = make_train_data(train_data)\n",
    "#valid_x, valid_y = make_valid_data(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e6bd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25996"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd6173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20dc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data  = np.array(X_data).reshape(-1, X_data[0].shape[0], X_data[0].shape[1])\n",
    "#train_x = np.array(X_data)\n",
    "Y_data = np.array(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720dbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x  = np.array(train_x).reshape(-1, train_x[0].shape[0], train_x[0].shape[1])\n",
    "#valid_x = np.array(valid_x)\n",
    "#valid_y = np.array(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ce37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(X_data,Y_data, test_size=0.1, shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aaa70c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23396, 288)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9061b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23396, 720, 11) (23396, 288)\n"
     ]
    }
   ],
   "source": [
    "train_x  = np.array(train_x).reshape(-1, train_x[0].shape[0], train_x[0].shape[1])\n",
    "train_y= np.array(train_y)\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "010424c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 720, 11) (2600, 288)\n"
     ]
    }
   ],
   "source": [
    "valid_x  = np.array(valid_x).reshape(-1, valid_x[0].shape[0], valid_x[0].shape[1])\n",
    "valid_y = np.array(valid_y)\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "968591bc",
   "metadata": {},
   "source": [
    "input dimension은 (Batch, Time_step, Feature dimension) 순이다. (batch_first=True)\n",
    "\n",
    "output이 288인 이유는 2일이라서\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be20ba",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e36986",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "270ce953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        \n",
    "        return torch.Tensor(self.X[index]) # 테스트셋 용\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb7414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeDataset(train_x, train_y)\n",
    "valid_dataset = TimeDataset(valid_x, valid_y)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, \n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1391110",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8efd1fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([32, 720, 11]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([32, 288]) type: torch.FloatTensor\n",
      "torch.Size([288])\n"
     ]
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f4a147c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([32, 720, 11]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([32, 288]) type: torch.FloatTensor\n",
      "torch.Size([288])\n"
     ]
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in valid_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630a2ff",
   "metadata": {},
   "source": [
    "# 모델\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8220ba",
   "metadata": {},
   "source": [
    "### input 설명\n",
    "\n",
    "- input_size: input의 feature dimension을 넣어주어야 한다. time step이 아니라 feature dimension!\n",
    "- hidden_size: 내부에서 어떤 feature dimension으로 바꿔주고 싶은지를 넣어주면 된다.\n",
    "- num_layers: lstm layer를 얼마나 쌓을지\n",
    "- bias: bias term을 둘 것인가 (Default: True)\n",
    "- batch_first: batch가 0번 dimension으로 오게 하려면 이거 설정! 난 이거 설정 가정하고 설명했다. (Default: False)\n",
    "- dropout: 가지치기 얼마나 할지, generalization 잘안되면 이걸 조정하면 된다.\n",
    "bidirectional: 양방향으로 할지 말지 (bidirectional 하면 [forward, backword] 로 feature dimension 2배 됨)\n",
    "\n",
    "\n",
    "\n",
    "참고.\n",
    "\n",
    "https://sanghyu.tistory.com/52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da3e174",
   "metadata": {},
   "source": [
    "### output 설명\n",
    "\n",
    "- outputs는 (output, (hidden or hidden stat,cell stat)) 의 tuple 형태로 나오므로 주의해서 써야한다. (LSTM만 cell state있음)\n",
    "- output: output dimension은 (batch, time_step, hidden dimension) 순이다. 양방향일 경우 hidden_size*2\n",
    "- hidden state: 모든 layer의 hidden state를 담고있다.\n",
    "- cell state: 모든 layer의 cell state를 담고있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bbb59d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 720, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=11, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "\n",
    "lstm(X_valid)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b7c4f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(X_valid)[0][-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaea8947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2125e-25, -1.4013e-45,  0.0000e+00,  ..., -5.1394e-19,\n",
       "           6.8985e-01, -1.0000e+00],\n",
       "         [-5.8491e-01,  1.0684e-19,  2.1312e-14,  ..., -3.1170e-09,\n",
       "           1.6982e-02, -1.0000e+00],\n",
       "         [ 7.3319e-01,  1.6223e-08, -6.1830e-09,  ..., -8.1642e-10,\n",
       "           9.3561e-12, -8.9369e-01],\n",
       "         ...,\n",
       "         [-8.6499e-09, -1.3424e-05,  8.0603e-12,  ..., -3.2270e-01,\n",
       "           9.9617e-01, -9.8948e-01],\n",
       "         [-1.3622e-11, -4.6491e-16,  2.0828e-14,  ..., -6.7423e-01,\n",
       "           1.0000e+00, -1.0000e+00],\n",
       "         [-2.0173e-07, -1.1269e-07,  1.0179e-08,  ..., -3.8466e-01,\n",
       "           9.1497e-01, -9.2854e-01]],\n",
       "\n",
       "        [[ 3.0079e-26,  1.0000e+00,  1.5087e-10,  ...,  7.7090e-01,\n",
       "          -3.0077e-14,  1.5602e-05],\n",
       "         [ 1.6971e-09,  1.0000e+00, -4.4272e-02,  ...,  1.0077e-01,\n",
       "          -2.7454e-10,  6.0517e-01],\n",
       "         [ 1.8537e-17,  1.0000e+00,  1.5693e-10,  ...,  9.9105e-01,\n",
       "           1.5102e-07,  2.7399e-03],\n",
       "         ...,\n",
       "         [-0.0000e+00, -1.0000e+00,  9.1794e-26,  ...,  9.9899e-01,\n",
       "           1.1716e-13,  5.5605e-06],\n",
       "         [ 4.0405e-26,  1.0000e+00,  7.9115e-14,  ...,  9.9588e-01,\n",
       "           4.0443e-15,  3.4343e-07],\n",
       "         [ 1.2016e-07, -9.9986e-01, -3.1795e-06,  ..., -7.6117e-01,\n",
       "          -1.1818e-05,  9.9977e-01]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(X_valid)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076c46b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(X_valid)[0][:,-2,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "525f9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x_input):\n",
    "        lstm_out, self.hidden = self.lstm(x_input)\n",
    "        return lstm_out, self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "502a9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsenc=lstm_encoder(input_size=11, hidden_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9207c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 720, 11, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.unsqueeze(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5fe70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden=lsenc(X_valid)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b880ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,num_layers = num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)           \n",
    "\n",
    "    def forward(self, x_input, encoder_hidden_states):\n",
    "        lstm_out, self.hidden = self.lstm(x_input.unsqueeze(1), encoder_hidden_states)\n",
    "        output = self.linear(lstm_out)\n",
    "        \n",
    "        return output, self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c6bbcb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[:,-1,:].unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7416f66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-9.9999e-01,  6.8152e-04, -9.9981e-01,  ..., -8.2503e-09,\n",
       "            1.8485e-10, -1.0000e+00],\n",
       "          [-9.9918e-01, -5.3212e-02, -9.2547e-01,  ..., -1.7359e-02,\n",
       "            1.1456e-05, -8.3623e-01],\n",
       "          [-9.5273e-01, -1.7715e-07,  1.6893e-12,  ..., -1.7547e-16,\n",
       "            1.0743e-05, -1.0000e+00],\n",
       "          ...,\n",
       "          [-3.5726e-01, -9.8880e-01, -4.0953e-01,  ..., -9.6264e-01,\n",
       "            2.5253e-01,  5.0742e-05],\n",
       "          [-4.8646e-01, -1.3008e-06, -5.5859e-04,  ..., -2.4223e-01,\n",
       "            5.7998e-01, -6.8880e-01],\n",
       "          [-4.2787e-04,  9.2575e-01, -8.4763e-02,  ..., -9.4322e-01,\n",
       "            7.0677e-01,  5.9411e-04]]], grad_fn=<StackBackward0>),\n",
       " tensor([[[-2.6212e+02,  4.2680e+00, -2.8583e+02,  ..., -8.5149e-09,\n",
       "            3.8020e-04, -7.6464e+01],\n",
       "          [-5.6660e+01, -3.2140e-01, -1.5016e+01,  ..., -2.1822e-02,\n",
       "            3.1523e-05, -1.2088e+00],\n",
       "          [-1.9117e+00, -8.4791e-01,  1.6893e-12,  ..., -1.7550e-16,\n",
       "            1.2152e+00, -2.4560e+01],\n",
       "          ...,\n",
       "          [-4.2522e-01, -1.8092e+01, -4.3732e-01,  ..., -2.2918e+00,\n",
       "            5.5999e-01,  5.4099e-05],\n",
       "          [-5.3980e-01, -2.9886e+00, -5.5859e-04,  ..., -1.0460e+00,\n",
       "            1.2574e+00, -8.4567e-01],\n",
       "          [-2.1717e-02,  1.6593e+00, -8.5159e-02,  ..., -2.5045e+00,\n",
       "            9.6777e-01,  6.1564e-04]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20c99a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[:,-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50d697fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3666, -0.2341, -0.1539, -0.0519,  0.0985,  0.1312,  0.0920,\n",
       "           -0.0640,  0.4623,  0.2326,  0.2723]],\n",
       " \n",
       "         [[-0.1382, -0.3967, -0.1811, -0.0653, -0.3343, -0.2210, -0.0997,\n",
       "           -0.1103, -0.0185,  0.0250, -0.0885]],\n",
       " \n",
       "         [[ 0.3870, -0.0714, -0.2172, -0.0700, -0.0418,  0.3539,  0.0987,\n",
       "           -0.2404,  0.2467,  0.2317, -0.0233]],\n",
       " \n",
       "         [[-0.1444, -0.5239,  0.1881,  0.0054, -0.1316,  0.1250,  0.3037,\n",
       "           -0.0329, -0.0814,  0.1071, -0.0014]],\n",
       " \n",
       "         [[-0.1105, -0.2824, -0.2677,  0.0718, -0.5790,  0.4682,  0.0898,\n",
       "           -0.4959, -0.2059, -0.0277, -0.1264]],\n",
       " \n",
       "         [[ 0.1965, -0.0706, -0.3865, -0.3186,  0.2734, -0.1299, -0.0438,\n",
       "           -0.5726, -0.0649, -0.3698, -0.1067]],\n",
       " \n",
       "         [[-0.1360, -0.1985, -0.2862,  0.1435, -0.6505,  0.3039,  0.3511,\n",
       "           -0.4397, -0.0957, -0.3001, -0.0420]],\n",
       " \n",
       "         [[-0.3309, -0.4086,  0.0808,  0.1474, -0.1413,  0.1920,  0.1884,\n",
       "           -0.3709, -0.3092, -0.1988,  0.2635]],\n",
       " \n",
       "         [[ 0.6868, -0.0436, -0.1994, -0.2235,  0.0211,  0.3168,  0.1278,\n",
       "            0.2625,  0.5561, -0.0042,  0.1957]],\n",
       " \n",
       "         [[-0.3029, -0.1524, -0.3888,  0.4074, -0.1559, -0.2741, -0.3300,\n",
       "           -0.6577, -0.6322,  0.0563, -0.1194]],\n",
       " \n",
       "         [[ 0.2818, -0.3813, -0.3696,  0.1504,  0.0424,  0.0635, -0.0807,\n",
       "            0.3770,  0.2603,  0.2682, -0.2550]],\n",
       " \n",
       "         [[ 0.3707, -0.3634, -0.4712, -0.0048,  0.0768,  0.2426,  0.2606,\n",
       "            0.2113,  0.3750,  0.2039, -0.0449]],\n",
       " \n",
       "         [[-0.0185, -0.1532, -0.1941, -0.1863,  0.2853,  0.0958, -0.1339,\n",
       "           -0.6942, -0.0017, -0.1062, -0.2304]],\n",
       " \n",
       "         [[ 0.1640, -0.5538, -0.2740, -0.0504, -0.2759,  0.3604,  0.3025,\n",
       "           -0.1749,  0.1274,  0.1648, -0.2437]],\n",
       " \n",
       "         [[ 0.1630, -0.3069, -0.2580,  0.0869, -0.1031, -0.1793,  0.2255,\n",
       "           -0.2958,  0.1327,  0.4657, -0.0103]],\n",
       " \n",
       "         [[-0.0673, -0.5303, -0.1196,  0.1256, -0.3597,  0.1841,  0.4239,\n",
       "           -0.1561, -0.2084, -0.0013,  0.0143]],\n",
       " \n",
       "         [[-0.2489, -0.3202, -0.2482, -0.2782, -0.4126,  0.0710,  0.2454,\n",
       "           -0.2549, -0.2460,  0.1486,  0.0441]],\n",
       " \n",
       "         [[-0.3947, -0.2741,  0.1544,  0.2012, -0.1783,  0.2762,  0.1963,\n",
       "           -0.3932, -0.1373, -0.1503,  0.4108]],\n",
       " \n",
       "         [[ 0.3058, -0.3796, -0.3418, -0.1286, -0.1404,  0.0935,  0.3944,\n",
       "           -0.1452,  0.0643, -0.0586,  0.0988]],\n",
       " \n",
       "         [[ 0.1843, -0.3553, -0.5478, -0.2567, -0.1035,  0.0433,  0.1942,\n",
       "           -0.3650, -0.0113, -0.0081,  0.0461]],\n",
       " \n",
       "         [[-0.2176, -0.4775,  0.0988, -0.0212, -0.2744, -0.0559,  0.2612,\n",
       "           -0.2777, -0.3564, -0.1076, -0.0507]],\n",
       " \n",
       "         [[ 0.2199, -0.4603, -0.1043, -0.3184, -0.1482, -0.0840,  0.1671,\n",
       "           -0.2295, -0.0645, -0.1779,  0.2730]],\n",
       " \n",
       "         [[-0.0825, -0.0875, -0.5473,  0.0885, -0.6518,  0.4498,  0.0346,\n",
       "           -0.6144, -0.3737, -0.0343, -0.0953]],\n",
       " \n",
       "         [[-0.1275, -0.4881, -0.0890, -0.0939, -0.3176,  0.1906,  0.3212,\n",
       "           -0.2345, -0.1610,  0.0810,  0.0388]],\n",
       " \n",
       "         [[-0.1794, -0.2881, -0.1781, -0.0457, -0.4768, -0.0466,  0.3579,\n",
       "           -0.2154, -0.3933,  0.2399,  0.0298]],\n",
       " \n",
       "         [[-0.1500,  0.0288,  0.0808,  0.4026, -0.0093, -0.0164,  0.4691,\n",
       "           -0.0752, -0.3114,  0.0358, -0.1631]],\n",
       " \n",
       "         [[ 0.3223, -0.0779, -0.1992, -0.1455, -0.3118, -0.1289,  0.3063,\n",
       "           -0.3551,  0.3693, -0.1870,  0.0629]],\n",
       " \n",
       "         [[-0.0040, -0.2504, -0.3711, -0.2209, -0.3674,  0.1003,  0.1281,\n",
       "           -0.4578, -0.5209,  0.1408,  0.1878]],\n",
       " \n",
       "         [[ 0.3040, -0.3518, -0.5130,  0.1698, -0.0477,  0.0954,  0.2248,\n",
       "            0.2011,  0.2626,  0.2232, -0.0993]],\n",
       " \n",
       "         [[-0.3747, -0.2719,  0.1791,  0.4143, -0.1578,  0.4109,  0.4620,\n",
       "           -0.2737, -0.1963, -0.2533,  0.2580]],\n",
       " \n",
       "         [[-0.3786, -0.2235, -0.4425,  0.2545, -0.3838,  0.5202,  0.1960,\n",
       "           -0.3168, -0.2199,  0.0380, -0.1273]],\n",
       " \n",
       "         [[ 0.6265, -0.0922, -0.2483, -0.2494, -0.0571,  0.3282,  0.1589,\n",
       "            0.2170,  0.5659,  0.0129,  0.1794]]], grad_fn=<AddBackward0>),\n",
       " (tensor([[[ 2.5037e-29,  1.5442e-11, -7.6096e-01,  ...,  3.9986e-01,\n",
       "             4.0638e-42,  1.3451e-22],\n",
       "           [ 7.9616e-20,  6.2329e-06, -3.1597e-01,  ...,  9.3755e-05,\n",
       "             6.7530e-20, -4.2296e-13],\n",
       "           [ 2.1662e-05, -6.4156e-06,  8.3132e-02,  ...,  7.6031e-01,\n",
       "             6.8253e-10,  4.6153e-04],\n",
       "           ...,\n",
       "           [ 2.0821e-17,  4.1771e-02, -5.2775e-03,  ...,  2.3247e-10,\n",
       "             1.5938e-13, -2.5105e-08],\n",
       "           [ 1.3325e-05,  4.3195e-03,  6.9300e-01,  ...,  5.9371e-04,\n",
       "             1.2811e-05, -6.0467e-04],\n",
       "           [ 5.6526e-32, -1.9001e-18,  6.2924e-01,  ...,  5.6495e-01,\n",
       "             0.0000e+00,  3.1760e-38]]], grad_fn=<StackBackward0>),\n",
       "  tensor([[[ 3.7349e-25,  3.7886e+00, -9.9999e-01,  ...,  4.2348e-01,\n",
       "             2.3546e-15,  1.2689e-03],\n",
       "           [ 1.1896e-15,  4.3217e+00, -9.9967e-01,  ...,  9.9632e-01,\n",
       "             1.3132e-02, -1.0000e+00],\n",
       "           [ 2.1693e-05, -6.8955e-01,  8.3479e-02,  ...,  9.9696e-01,\n",
       "             4.0951e-01,  5.4263e-01],\n",
       "           ...,\n",
       "           [ 4.0172e-11,  2.3562e+02, -8.9977e-01,  ...,  9.9668e-01,\n",
       "             2.4269e+01, -1.0000e+00],\n",
       "           [ 4.2628e-05,  2.5158e+02,  8.5432e-01,  ...,  6.0462e-04,\n",
       "             9.9985e-01, -9.9995e-01],\n",
       "           [ 5.6566e-32, -2.3452e+00,  1.0000e+00,  ...,  6.4007e-01,\n",
       "             5.0390e-35,  6.1710e-01]]], grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsde = lstm_decoder(input_size=11, hidden_size=256)\n",
    "lsde(X_valid[:,-1,:] , hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61569f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_encoder_decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(lstm_encoder_decoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = lstm_encoder(input_size = input_size, hidden_size = hidden_size)\n",
    "        self.decoder = lstm_decoder(input_size = input_size, hidden_size = hidden_size)\n",
    "\n",
    "    def forward(self, inputs, targets, target_len, teacher_forcing_ratio):\n",
    "        batch_size = inputs.shape[0]\n",
    "        input_size = inputs.shape[2]\n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, input_size)\n",
    "\n",
    "        _, hidden = self.encoder(inputs)\n",
    "        decoder_input = inputs[:,-1, :]\n",
    "        \n",
    "        for t in range(target_len): \n",
    "            out, hidden = self.decoder(decoder_input, hidden)\n",
    "            out =  out.squeeze(1)\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                decoder_input = targets[:, t, :] #원래 seq2seq는 이전 프레임의 예측값을 넣어주는데. tf는 실제 타겟값으로 넣어준다.\n",
    "            else:\n",
    "                decoder_input = out\n",
    "            outputs[:,t,:] = out\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def predict(self, inputs, target_len):\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        self.eval()\n",
    "        batch_size = inputs.shape[0]\n",
    "        input_size = inputs.shape[2]\n",
    "        outputs = torch.zeros(batch_size, target_len, input_size)\n",
    "        _, hidden = self.encoder(inputs)\n",
    "        decoder_input = inputs[:,-1, :]\n",
    "        for t in range(target_len): \n",
    "            out, hidden = self.decoder(decoder_input, hidden)\n",
    "            out =  out.squeeze(1)\n",
    "            decoder_input = out\n",
    "            outputs[:,t,:] = out\n",
    "        return outputs.detach().numpy()[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2bc30f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 720, 11])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f77911fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 288, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid.unsqueeze(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90abfb0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 11, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7524/2304093171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlsed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlstm_encoder_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m288\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## 11 ->1 이 되도록 수정이 필요하다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7524/673247701.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, targets, target_len, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7524/2611591427.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_input, encoder_hidden_states)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                            ):\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m    207\u001b[0m                     self.input_size, input.size(-1)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 11, got 1"
     ]
    }
   ],
   "source": [
    "lsed=lstm_encoder_decoder(11,256)\n",
    "lsed(inputs=X_valid,targets=Y_valid.unsqueeze(-1), target_len=288, teacher_forcing_ratio=0.6)\n",
    "\n",
    "## 11 ->1 이 되도록 수정이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e20c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=11, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512,512),# 사이즈는 hidden size에 따라 결정.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,288), #결과 288개 예측.\n",
    "            nn.ReLU(),  \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.classifier(output[:,-1,:]) # -1은 hidden state의 마지막 time step값을 가져온 것.\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8304e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_mae_loss = 0\n",
    "    for batch_idx,(X, Y) in enumerate(train_loader):\n",
    "        X = X.to(DEVICE)\n",
    "        Y = Y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()#데이터들 장비에 할당\n",
    "        output = model(X) # model로 output을 계산\n",
    "        loss = criterion(output, Y)        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mae = metric(output, Y)\n",
    "            train_mae_loss+=mae.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_mae_loss/=len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss,train_mae_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cad0878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_mae = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for X, Y in valid_loader:\n",
    "            X = X.to(DEVICE)\n",
    "            Y = Y.to(DEVICE)\n",
    "            output = model(X,) # model로 output을 계산\n",
    "            \n",
    "            loss = criterion(output, Y)\n",
    "            valid_loss += loss.item()\n",
    "            mae = metric(output, Y)\n",
    "            valid_mae+=mae.item()\n",
    "    valid_loss/=len(valid_loader.dataset)\n",
    "    valid_mae/=len(valid_loader.dataset)\n",
    "    return valid_loss, valid_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce9f1630",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/checkpoint_seq2seq.pt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'targets', 'target_len', and 'teacher_forcing_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7524/210802379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mEpoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7524/850493066.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#데이터들 장비에 할당\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# model로 output을 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'targets', 'target_len', and 'teacher_forcing_ratio'"
     ]
    }
   ],
   "source": [
    "#학습 진행 코드\n",
    "\n",
    "\n",
    "check_path = './checkpoint/checkpoint_seq2seq.pt'\n",
    "print(check_path)\n",
    "model = lstm_encoder_decoder(11,256).to(DEVICE)\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "metric = nn.L1Loss().to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "best_valid_mae = 999999\n",
    "best_valid_loss = 9999999999\n",
    "\n",
    "\n",
    "\n",
    "for Epoch in range(1,EPOCHS+1):\n",
    "    train_loss,train_mae = train(model,train_loader,optimizer,log_interval=31)\n",
    "    valid_loss,valid_mae = evaluate(model, valid_loader)\n",
    "    \n",
    "    \n",
    "    print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train MAE:{:.4f}  | \\tValid Loss:{:.4f} \\tValid MAE: {:.4f}\\n\".\n",
    "                  format(Epoch, train_loss, train_mae,\n",
    "                         valid_loss, valid_mae ))\n",
    "    if best_valid_loss > valid_loss:\n",
    "        print(\"-- SAVE Checkpoint --\")\n",
    "        print(\"Valid loss : {:.4f} -> {:.4f} \\n\".format(best_valid_loss,valid_loss ))\n",
    "        torch.save(model.state_dict(), check_path, _use_new_zipfile_serialization=False)\n",
    "        best_valid_mae = valid_mae\n",
    "        best_valid_loss =valid_loss\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe62e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddddd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e39bf",
   "metadata": {},
   "source": [
    "# validation 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8da1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valid loss : {:.4f} / Valid MAE : {:.4f} \\n\".format(best_valid_loss,best_valid_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valid loss : {:.4f} / Valid MAE : {:.4f} \\n\".format(best_valid_loss,best_valid_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2834d",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42905079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 이전 5일치 가져오기.\n",
    "test_data_list = [x for x in range(196, 201)]\n",
    "\n",
    "test_data = train_data[train_data[\"Day\"].isin(test_data_list)]\n",
    "\n",
    "test_data = test_data.drop([\"TurbID\", \"Day\"], axis = 1)\n",
    "\n",
    "test_data = np.array(test_data).reshape(-1, train_x[0].shape[0], train_x[0].shape[1])\n",
    "#train set 처럼 batch,720,11로 고치기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeDataset(test_data, None)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63255878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(iter(test_loader)):\n",
    "            X = X.to(DEVICE)\n",
    "            \n",
    "            pred = model(X)\n",
    "            preds += pred.cpu().tolist()\n",
    "    \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel().to(DEVICE)\n",
    "best_checkpoint = torch.load('./checkpoint/checkpoint_baseline.pt')\n",
    "model.load_state_dict(best_checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb758521",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, test_loader)\n",
    "preds = preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919698",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"Patv\"] = preds\n",
    "sample_submission.to_csv(\"./submit.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd8f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
